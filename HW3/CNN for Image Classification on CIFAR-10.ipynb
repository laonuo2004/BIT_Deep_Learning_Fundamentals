{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 图像分类：初步实现\n",
    "\n",
    "本笔记旨在记录使用 PyTorch 构建卷积神经网络 (CNN) 完成 CIFAR-10 图像分类任务的完整流程。重点在于理解并实现包括数据加载、预处理、模型构建（特别是深度可分离卷积的应用）、训练、评估及结果可视化等关键环节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入所需库\n",
    "\n",
    "首先，导入研究所需的 Python 库。核心库包括 `torch` (PyTorch 深度学习框架)，`torchvision` (处理计算机视觉任务，包含数据集、模型和图像变换)，`matplotlib` (用于绘图)，以及 `sklearn.metrics` (用于计算混淆矩阵)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422cbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns # 用于更美观的混淆矩阵可视化\n",
    "\n",
    "# 用于在 Notebook 中显示 matplotlib 图像\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93683c9a",
   "metadata": {},
   "source": [
    "### 2. 设备配置与超参数设定\n",
    "\n",
    "检查 CUDA 是否可用，以决定使用 GPU 还是 CPU 进行训练。同时，定义一些关键的超参数，如学习率、批次大小和训练周期数。这些参数后续可进行调整以优化模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc77cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前使用的设备是: {device}\")\n",
    "\n",
    "# 定义超参数\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64 # 初始批次大小，可根据显存调整\n",
    "EPOCHS = 50      # 初始训练周期，后续可增加\n",
    "\n",
    "# CIFAR-10 类别\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac83920",
   "metadata": {},
   "source": [
    "### 3. 数据加载、预处理与增强\n",
    "\n",
    "此步骤涉及 CIFAR-10 数据集的加载与准备。关键操作包括：\n",
    "1.  **数据变换 (Transforms):** 定义一系列针对训练集和测试集的预处理操作。\n",
    "    *   `ToTensor()`: 将 PIL 图像或 NumPy `ndarray` 转换为 `FloatTensor`，并将图像的像素值范围从 [0, 255] 归一化到 [0.0, 1.0]。\n",
    "    *   `Normalize(mean, std)`: 用给定的均值 (mean) 和标准差 (std) 对张量图像进行归一化。此操作有助于加速模型收敛并提高稳定性。CIFAR-10 数据集常用的均值和标准差为 `(0.4914, 0.4822, 0.4465)` 和 `(0.2023, 0.1994, 0.2010)`，参考[https://stackoverflow.com/a/68123869/29793656](https://stackoverflow.com/a/68123869/29793656)\n",
    "    *   **数据增强 (Data Augmentation):** 仅对训练集应用，以增加数据多样性，提高模型泛化能力。例如 `RandomHorizontalFlip()` (随机水平翻转) 和 `RandomCrop()` (随机裁剪)等。\n",
    "2.  **数据集下载与加载:** 使用 `torchvision.datasets.CIFAR10` 下载并加载数据集。\n",
    "3.  **数据加载器 (DataLoader):** 使用 `torch.utils.data.DataLoader` 创建数据加载器，以便在训练和测试过程中高效地批量加载数据，并支持数据打乱 (`shuffle=True` for training)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dccb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集的数据增强和预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), # 随机水平翻转\n",
    "    transforms.RandomHorizontalFlip(), # 随机裁剪\n",
    "    transforms.RandomRotation(15), # 随机旋转\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # 颜色抖动\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 测试集的 transform_test 通常保持不变\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 训练集和测试集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2) # num_workers用于多进程加载数据\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"训练集样本数: {len(trainset)}\")\n",
    "print(f\"测试集样本数: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55827f45",
   "metadata": {},
   "source": [
    "### 4. 模型定义 (卷积神经网络与深度可分离卷积)\n",
    "\n",
    "构建卷积神经网络模型。根据要求，模型需包含**深度可分离卷积 (Depthwise Separable Convolution)**。深度可分离卷积将标准卷积分解为两个步骤：\n",
    "1.  **深度卷积 (Depthwise Convolution):** 对每个输入通道独立应用一个卷积核。通过 `nn.Conv2d` 的 `groups` 参数实现，当 `groups` 等于输入通道数 `in_channels` 时，即为深度卷积。\n",
    "2.  **逐点卷积 (Pointwise Convolution):** 一个标准的 1x1 卷积，用于组合深度卷积产生的特征图，并调整通道数。\n",
    "\n",
    "首先定义一个深度可分离卷积模块，然后将其集成到主网络结构中。网络结构可以包含若干卷积层、深度可分离卷积层、激活函数 (如 ReLU)、池化层 (如 MaxPool2d) 和全连接层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"深度可分离卷积模块\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        # 深度卷积: groups=in_channels 使得每个输入通道独立进行卷积\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   stride=stride, padding=padding, groups=in_channels, bias=False)\n",
    "        self.bn_depthwise = nn.BatchNorm2d(in_channels) # 在深度卷积后接BN\n",
    "        # 逐点卷积: 1x1 卷积\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn_pointwise = nn.BatchNorm2d(out_channels) # 在逐点卷积后接BN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn_depthwise(x)\n",
    "        x = F.relu(x) # 激活函数\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn_pointwise(x)\n",
    "        x = F.relu(x) # 激活函数\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 初始卷积层，可以适当增加初始通道数\n",
    "        self.conv1 = nn.Conv2d(3, 48, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(48)\n",
    "        \n",
    "        # 第一个深度可分离卷积层，增加输出通道\n",
    "        self.dsc1 = DepthwiseSeparableConv(48, 96, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 2x2 Max Pooling\n",
    "        self.dropout1 = nn.Dropout(0.25) # Dropout层防止过拟合\n",
    "\n",
    "        # 第二个深度可分离卷积层，增加输出通道\n",
    "        self.dsc2 = DepthwiseSeparableConv(96, 192, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        # 第三个深度可分离卷积层，增加输出通道\n",
    "        self.dsc3 = DepthwiseSeparableConv(192, 384, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        \n",
    "        # 全连接层\n",
    "        # 输入尺寸计算: 初始32x32 -> pool1后16x16 -> pool2后8x8 -> pool3后4x4\n",
    "        # 因此，flatten后的特征数量为 384 * 4 * 4\n",
    "        self.fc1 = nn.Linear(384 * 4 * 4, 512) \n",
    "        self.dropout_fc = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10) # CIFAR-10 有10个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.dsc1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.dsc2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.dsc3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = x.view(-1, 384 * 4 * 4) # Flatten操作\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x) # 输出层不需要激活函数，因为CrossEntropyLoss会处理\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b261186",
   "metadata": {},
   "source": [
    "#### 以下是该模型的网络架构图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "class Mermaid:\n",
    "    def __init__(self, diagram: str):\n",
    "        self._diagram = self._process_diagram(diagram)\n",
    "        self._uid = uuid.uuid4()\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_diagram(diagram: str) -> str:\n",
    "        _diagram = diagram.replace(\"\\n\", \"\\\\n\")\n",
    "        _diagram = _diagram.lstrip(\"\\\\n\")\n",
    "        _diagram = _diagram.replace(\"'\", '\"')\n",
    "        return _diagram\n",
    "\n",
    "    def _repr_html_(self) -> str:\n",
    "        ret = f\"\"\"\n",
    "        <div class=\"mermaid-{self._uid}\" style=\"background-color: white;\"></div>\n",
    "        <script type=\"module\">\n",
    "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
    "            const graphDefinition = '{self._diagram}';\n",
    "            const element = document.querySelector('.mermaid-{self._uid}');\n",
    "            const {{ svg }} = await mermaid.render('graphDiv-{self._uid}', graphDefinition);\n",
    "            element.innerHTML = svg;\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        return ret\n",
    "\n",
    "Mermaid(\"\"\"\n",
    "graph LR\n",
    "    A--> B\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51afbf84",
   "metadata": {},
   "source": [
    "### 5. 定义损失函数与优化器\n",
    "\n",
    "对于多分类任务，常用的损失函数是**交叉熵损失 (Cross-Entropy Loss)**，在 PyTorch 中通过 `nn.CrossEntropyLoss()` 实现。该损失函数内部集成了 `LogSoftmax` 和 `NLLLoss`，因此模型输出层通常不需要显式添加 Softmax激活函数。\n",
    "\n",
    "选择**优化器 (Optimizer)** 来更新模型的权重。Adam 优化器 (`optim.Adam`) 是一种常用的自适应学习率优化算法，通常具有较好的性能。\n",
    "\n",
    "为进一步优化学习过程，我们可以采用余弦退火学习率调度器 (`torch.optim.lr_scheduler.CosineAnnealingLR`)。该调度器依据余弦函数曲线，在指定的周期 (`T_max`) 内将学习率从初始值**平滑地**降低至一个设定的最小值 (`eta_min`)。这种策略有助于模型在训练后期更稳定地收敛，从而达到更优的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65792921",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # Adam优化器\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=0.00001) # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42bbcda",
   "metadata": {},
   "source": [
    "### 6. 训练模型\n",
    "\n",
    "训练过程在一个循环中进行，每个循环代表一个**训练周期 (Epoch)**。在每个周期内，模型遍历整个训练数据集。\n",
    "对于每个批次 (Batch) 的数据：\n",
    "1.  将数据和标签移动到指定设备 (GPU/CPU)。\n",
    "2.  **梯度清零:** `optimizer.zero_grad()`，清除上一轮迭代的梯度信息。\n",
    "3.  **前向传播:** `outputs = model(inputs)`，将输入数据送入模型，得到预测输出。\n",
    "4.  **计算损失:** `loss = criterion(outputs, labels)`，根据预测输出和真实标签计算损失。\n",
    "5.  **反向传播:** `loss.backward()`，计算损失相对于模型参数的梯度。\n",
    "6.  **参数更新:** `optimizer.step()`，根据梯度更新模型参数。\n",
    "\n",
    "在训练过程中，可以记录并打印每个周期的平均训练损失和准确率，以监控训练状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, criterion, optimizer, epochs, scheduler=None):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0) # 乘以batch_size以得到总损失\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i + 1) % 100 == 0: # 每100个mini-batches打印一次信息\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}结束: 平均训练损失: {epoch_loss:.4f}, 训练准确率: {epoch_accuracy:.4f}')\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f'调用学习率调度器， 当前学习率: {current_lr:.6f}')\n",
    "    \n",
    "    print('训练完成')\n",
    "    return train_losses, train_accuracies\n",
    "\n",
    "# 开始训练\n",
    "train_losses, train_accuracies = train_model(model, trainloader, criterion, optimizer, epochs=EPOCHS, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48ec67",
   "metadata": {},
   "source": [
    "### 7. 评估模型\n",
    "\n",
    "在模型训练完成后，使用测试数据集评估其性能。评估过程与训练类似，但不进行梯度计算和参数更新。\n",
    "1.  将模型设置为评估模式: `model.eval()`。这会关闭 Dropout 和 BatchNorm 的更新等特定于训练的行为。\n",
    "2.  使用 `torch.no_grad()` 上下文管理器，禁用梯度计算，以减少内存消耗并加速计算。\n",
    "3.  遍历测试数据加载器，计算总损失和准确率。\n",
    "4.  收集所有真实标签和预测标签，用于后续的混淆矩阵和样本可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6db0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader, criterion):\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad(): # 在评估阶段不计算梯度\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy()) # 收集真实标签\n",
    "            all_predictions.extend(predicted.cpu().numpy()) # 收集预测标签\n",
    "\n",
    "    avg_test_loss = test_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    print(f'测试集: 平均损失: {avg_test_loss:.4f}, 准确率: {correct_predictions}/{total_samples} ({accuracy:.2%})')\n",
    "    return avg_test_loss, accuracy, all_labels, all_predictions\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_accuracy, true_labels, pred_labels = evaluate_model(model, testloader, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444ceed",
   "metadata": {},
   "source": [
    "### 8. 结果可视化\n",
    "\n",
    "可视化有助于更直观地理解模型的性能和行为。\n",
    "\n",
    "#### 8.1 训练过程可视化 (损失与准确率曲线)\n",
    "绘制训练过程中的损失和准确率曲线，可以观察模型的收敛情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92776304",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, EPOCHS + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 混淆矩阵 (Confusion Matrix)\n",
    "\n",
    "混淆矩阵清晰地展示了模型在各个类别上的分类情况，特别是哪些类别容易被混淆。使用 `sklearn.metrics.confusion_matrix` 计算，并用 `seaborn.heatmap` 或 `matplotlib.pyplot.imshow` 进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 样本图片、真实标签与预测标签展示\n",
    "\n",
    "随机抽取一部分测试集图片，展示其真实图像、真实标签以及模型的预测标签。这有助于直观感受模型的分类效果。\n",
    "注意：由于数据加载时进行了归一化，显示图像前需要进行**反归一化**操作，以还原图像的原始像素值范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_with_predictions(img_tensor, title):\n",
    "    \"\"\"显示反归一化后的图像及其标题\"\"\"\n",
    "    # 反归一化: PyTorch中的图像是 C x H x W, Matplotlib 需要 H x W x C\n",
    "    # 均值和标准差 (与预处理时一致)\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2023, 0.1994, 0.2010])\n",
    "    \n",
    "    img_np = img_tensor.numpy().transpose((1, 2, 0)) # C,H,W -> H,W,C\n",
    "    img_np = std * img_np + mean # 反归一化\n",
    "    img_np = np.clip(img_np, 0, 1) # 将像素值限制在 [0, 1] 范围内\n",
    "    \n",
    "    plt.imshow(img_np)\n",
    "    plt.title(title)\n",
    "    plt.axis('off') # 不显示坐标轴\n",
    "\n",
    "def visualize_predictions(dataset, model, num_images=25):\n",
    "    \"\"\"可视化一部分测试图片的真实标签和预测标签\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 计算总行数和列数，尽量使图像排列成方形\n",
    "    cols = int(np.ceil(np.sqrt(num_images)))\n",
    "    rows = int(np.ceil(num_images / cols))\n",
    "    \n",
    "    plt.figure(figsize=(cols * 2, rows * 2.2)) # 调整图像大小\n",
    "    \n",
    "    indices = np.random.choice(len(dataset), num_images, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img_tensor, label = dataset[idx] # 直接从 dataset 获取原始Tensor和标签\n",
    "        img_for_model = img_tensor.unsqueeze(0).to(device) # 增加batch维度并移至设备\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img_for_model)\n",
    "            _, predicted_idx = torch.max(output, 1)\n",
    "        \n",
    "        predicted_class = classes[predicted_idx.item()]\n",
    "        true_class = classes[label]\n",
    "        \n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        title = f\"True: {true_class}\\nPred: {predicted_class}\"\n",
    "        if predicted_class != true_class:\n",
    "            title = f\"{title} (Wrong)\" # 标记错误预测\n",
    "        \n",
    "        # 注意：imshow_with_predictions 需要的是原始的、未经过 transform_test 中 ToTensor 之外操作的图像张量\n",
    "        # 但我们这里是从 dataset 中取出的已经是 transform 后的，所以直接使用即可\n",
    "        imshow_with_predictions(img_tensor.cpu(), title)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 可视化测试集中的预测结果 (注意: testset 包含的是已经 transform 过的图像)\n",
    "visualize_predictions(testset, model, num_images=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 保存模型\n",
    "\n",
    "训练完成后，可以将模型的**状态字典 (state_dict)** 保存到磁盘。状态字典包含了模型的所有可学习参数 (权重和偏置)。后续可以通过加载此状态字典来恢复模型，进行进一步的训练、评估或部署。\n",
    "使用 `torch.save(model.state_dict(), PATH)` 保存，使用 `model.load_state_dict(torch.load(PATH))` 和 `model.to(device)` 加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'cifar10_cnn_depthwise_sep.pth'\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"模型已保存到: {MODEL_PATH}\")\n",
    "\n",
    "# 如何加载模型 (示例):\n",
    "# model_loaded = Net().to(device)\n",
    "# model_loaded.load_state_dict(torch.load(MODEL_PATH))\n",
    "# model_loaded.eval() # 设置为评估模式"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
