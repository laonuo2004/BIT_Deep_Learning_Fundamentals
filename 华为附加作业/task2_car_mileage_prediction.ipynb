{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验二：汽车里程数回归预测\n",
    "\n",
    " 本次实验旨在利用前馈神经网络，根据汽车的多种属性，预测其每加仑行驶的英里数（MPG）。\n",
    " 我们将使用MindSpore框架来构建、训练和评估一个回归模型。\n",
    "\n",
    " **学生视角思考**：\n",
    " 这个任务是一个典型的回归问题。与分类问题不同，我们的目标是预测一个连续值（MPG），而不是一个离散的类别。\n",
    " 因此，模型的输出层不会使用Softmax激活函数，损失函数也应该选用适合回归任务的，比如均方误差（MSE）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备与库导入\n",
    "\n",
    " 首先，我们需要导入所有必要的库。\n",
    " - `os`, `csv`, `time`: 用于基本操作。\n",
    " - `numpy`, `pandas`: 用于数据处理和分析。\n",
    " - `matplotlib`: 用于数据可视化。\n",
    " - `mindspore`: 核心的深度学习框架。\n",
    "\n",
    " 同时，我们需要根据实验要求设置MindSpore的运行环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.context as context\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore import nn, Tensor\n",
    "from mindspore.train import Model\n",
    "from mindspore.nn.metrics import Accuracy, MAE, MSE\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置MindSpore的执行模式为图模式，并指定使用Ascend硬件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE, device_target='Ascend')#| ## 2. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们加载 `auto-mpg.data` 数据集。这个数据集记录了不同汽车的多种属性以及它们的MPG。\n",
    "\n",
    " **学生视角思考**：\n",
    " 数据预处理是机器学习项目中至关重要的一步。原始数据往往是不规整的，可能包含缺失值、非数值特征等。\n",
    " - **缺失值处理**: 我注意到数据中的马力（Horsepower）列有 `?` 作为缺失值。Pandas在读取时可以方便地将它们识别为NaN，然后我可以直接删除这些行，因为缺失的数据量不大。\n",
    " - **特征编码**: 'Origin' (产地) 是一个分类特征（1: USA, 2: Europe, 3: Japan）。神经网络需要数值输入，所以需要将其转换为one-hot编码。这样模型就不会错误地认为产地之间存在序数关系（比如Japan > Europe）。\n",
    " - **数据归一化**: 不同特征的数值范围差异很大（例如，`Weight` 和 `Cylinders`）。如果不进行归一化，范围较大的特征可能会在模型训练中占据主导地位，导致收敛缓慢或结果不佳。我将使用标准差归一化（Z-score normalization）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 加载数据\n",
    " 我们使用 `pandas` 直接从URL读取数据，并指定列名和处理方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ascend-professional-construction-dataset.obs.cn-north-4.myhuaweicloud.com/deep-learning/auto-mpg.data'\n",
    "\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "print(\"原始数据集（前5行）:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 清理数据（处理缺失值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n缺失值统计:\")\n",
    "print(dataset.isna().sum())\n",
    "\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 特征工程（One-Hot编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('Origin')\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "print(\"\\n进行One-Hot编码后（后5行）:\")\n",
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "\n",
    "print(\"\\n归一化后的训练数据（前5行）:\")\n",
    "print(normed_train_data.head())#| ## 3. 构建神经网络模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将构建一个包含两个隐藏层的全连接神经网络。\n",
    "\n",
    " **学生视角思考**:\n",
    " - **网络结构**: 对于这种表格数据回归任务，一个简单的全连接网络通常就足够了。我设计了`9 -> 64 -> 64 -> 1`的结构。输入层有9个神经元，对应9个特征。两个隐藏层各有64个神经元，这提供了一定的模型容量来学习复杂的非线性关系。输出层只有1个神经元，直接输出预测的MPG值。\n",
    " - **激活函数**: 我在隐藏层之间使用了ReLU激活函数，这是深度学习中最常用的激活函数之一，因为它计算简单且能有效避免梯度消失问题。\n",
    " - **输出层**: 输出层没有激活函数，因为我们需要它输出任意范围的连续值，而不是像分类任务那样限制在特定范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(9, 64, activation='relu')\n",
    "        self.fc2 = nn.Dense(64, 64, activation='relu')\n",
    "        self.fc3 = nn.Dense(64, 1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x#| ## 4. 模型训练与评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来定义训练过程。\n",
    "\n",
    " **学生视角思考**:\n",
    " - **损失函数**: 我选择了均方误差（MSE, Mean Square Error）作为损失函数，这是回归问题最常用的损失函数，它衡量了预测值与真实值之间差的平方的均值。\n",
    " - **优化器**: 我使用了RMSProp优化器。它是一种自适应学习率的优化器，通常在处理非平稳目标时表现良好。\n",
    " - **评估指标**: 除了MSE，我还将监控平均绝对误差（MAE, Mean Absolute Error）。MAE直接衡量预测值与真实值之间差的绝对值的均值，它的单位与目标变量相同，因此更易于解释。例如，MAE为3.5意味着模型的预测平均偏离真实MPG值3.5个单位。\n",
    " - **训练循环**: 我将训练100个epoch。在每个epoch结束时，我会在测试集上评估模型，并保存MAE和MSE，以便后续可视化模型的学习过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 定义超参数、模型、损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "network = RegressionNet()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = nn.RMSProp(network.trainable_params(), learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "grad_fn = ops.GradOperation(get_by_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_mae': [], 'test_loss': [], 'test_mae': []}\n",
    "\n",
    "# 将数据转为Tensor\n",
    "X_train = Tensor(normed_train_data.values, ms.float32)\n",
    "Y_train = Tensor(train_labels.values.reshape(-1, 1), ms.float32)\n",
    "X_test = Tensor(normed_test_data.values, ms.float32)\n",
    "Y_test = Tensor(test_labels.values.reshape(-1, 1), ms.float32)\n",
    "\n",
    "mae_metric = MAE()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 手动计算梯度\n",
    "    loss = loss_fn(network(X_train), Y_train)\n",
    "    grads = grad_fn(network, optimizer.parameters)(X_train)\n",
    "    optimizer(grads)\n",
    "\n",
    "    # 记录训练集指标\n",
    "    mae_metric.clear()\n",
    "    mae_metric.update(network(X_train), Y_train)\n",
    "    train_mae = mae_metric.eval()\n",
    "    \n",
    "    history['train_loss'].append(loss.asnumpy())\n",
    "    history['train_mae'].append(train_mae)\n",
    "\n",
    "    # 评估测试集\n",
    "    test_predictions = network(X_test)\n",
    "    test_loss = loss_fn(test_predictions, Y_test)\n",
    "    \n",
    "    mae_metric.clear()\n",
    "    mae_metric.update(test_predictions, Y_test)\n",
    "    test_mae = mae_metric.eval()\n",
    "\n",
    "    history['test_loss'].append(test_loss.asnumpy())\n",
    "    history['test_mae'].append(test_mae)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {loss.asnumpy():.4f}, Test Loss: {test_loss.asnumpy():.4f}, Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 可视化训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(history['train_mae'], label='Train Error')\n",
    "    plt.plot(history['test_mae'], label = 'Val Error')\n",
    "    plt.ylim([0, 5])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(history['train_loss'], label='Train Error')\n",
    "    plt.plot(history['test_loss'], label='Val Error')\n",
    "    plt.ylim([0, 25])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 可视化预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = network(X_test).asnumpy()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 实验总结\n",
    "\n",
    " 通过本次实验，我成功地使用MindSpore构建了一个前馈神经网络来解决汽车里程数的回归预测问题。\n",
    " 从训练过程的MAE和MSE曲线可以看出，模型在大约20个epoch后迅速收敛，并且在训练集和验证集上的误差都保持在较低水平，没有出现明显的过拟合。\n",
    " 最终的预测值与真实值散点图也显示，大部分点都紧密地分布在对角线附近，说明模型具有较好的预测精度。\n",
    " 我深刻体会到了数据预处理（特别是归一化）对模型训练的重要性，以及如何为回归任务选择合适的网络结构、损失函数和评估指标。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
