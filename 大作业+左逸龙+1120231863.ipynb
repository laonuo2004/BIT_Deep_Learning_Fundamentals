{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ·±åº¦å­¦ä¹ åŸºç¡€å¤§ä½œä¸šï¼šå®¤å†…å°ç‰©ä½“æ£€æµ‹\n",
    "\n",
    " **ä½œè€…**: å·¦é€¸é¾™ (å­¦å·: 1120231863)\n",
    " **Codelabè´¦å·**: laonuo2004\n",
    "\n",
    " ---\n",
    "\n",
    " ## 1. é¡¹ç›®æ¦‚è§ˆä¸ç›®æ ‡\n",
    "\n",
    " æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å®¤å†…å°ç‰©ä½“æ£€æµ‹ä»»åŠ¡ã€‚ä»»åŠ¡æºè‡ªCOCOæ•°æ®é›†çš„å­é›†ï¼ŒåŒ…å«äº†21ä¸ªç±»åˆ«çš„å¸¸è§å®¤å†…ç‰©å“ã€‚é¡¹ç›®çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºç‰©ä½“å°ºå¯¸å°ã€æ•°é‡å¤šã€å­˜åœ¨é®æŒ¡ä»¥åŠä¸¥é‡çš„ç±»åˆ«ä¸å‡è¡¡é—®é¢˜ã€‚\n",
    "\n",
    "è€ƒè™‘åˆ°æˆ‘ä¹‹å‰åœ¨ HW4 å½“ä¸­æœ‰è°ƒç ”è¿‡ YOLO ç³»åˆ—æ¨¡å‹(å°¤å…¶æ˜¯é˜…è¯»è¿‡ YOLOv5 çš„æºç )ï¼Œå› æ­¤æˆ‘å†³å®šä½¿ç”¨ YOLOv8 ä½œä¸ºæœ¬é¡¹ç›®çš„åŸºç¡€æ¨¡å‹ã€‚\n",
    "\n",
    " **æœ€ç»ˆç›®æ ‡**:\n",
    " 1.  å®ç°ä¸€ä¸ªé«˜ç²¾åº¦ã€é«˜æ•ˆç‡çš„YOLOv8æ£€æµ‹æ¨¡å‹ã€‚\n",
    " 2.  åœ¨æ»¡è¶³æ¯”èµ›è§„åˆ™ï¼ˆç¦æ­¢ä½¿ç”¨COCOæ£€æµ‹é¢„è®­ç»ƒæƒé‡ï¼‰çš„å‰æä¸‹ï¼Œå°½å¯èƒ½æå‡`mAP@0.5:0.95`æŒ‡æ ‡ã€‚\n",
    " 3.  äº§å‡ºä¸€ä»½ç»“æ„æ¸…æ™°ã€ä»£ç è§„èŒƒã€å¯å®Œæ•´å¤ç°çš„Jupyter NotebookæŠ¥å‘Šã€‚\n",
    "\n",
    " ---\n",
    "\n",
    " ## 2. æœ€ç»ˆå®ç°ç­–ç•¥\n",
    "\n",
    " æˆ‘åœ¨ä»£ç å½“ä¸­é›†æˆäº†å¤šç§ä¼˜åŒ–æ–¹æ³•ï¼š\n",
    "\n",
    " - **æ¨¡å‹æ¶æ„åˆ›æ–° (æ ¸å¿ƒåŠ åˆ†é¡¹)**: ä½¿ç”¨**BiFPN (Bi-directional Feature Pyramid Network)** æ›¿æ¢äº†YOLOv8åŸç”Ÿçš„PANeté¢ˆéƒ¨ç»“æ„ã€‚BiFPNé€šè¿‡é«˜æ•ˆçš„åŒå‘è·¨å°ºåº¦è¿æ¥å’ŒåŠ æƒç‰¹å¾èåˆï¼Œèƒ½æ›´å¥½åœ°å¤„ç†ä¸åŒå°ºåº¦çš„ç‰©ä½“ï¼Œå°¤å…¶é€‚åˆæœ¬é¡¹ç›®ä¸­çš„å°ç‰©ä½“æ£€æµ‹åœºæ™¯ã€‚\n",
    " - **ä¸¥æ ¼çš„é¢„è®­ç»ƒç­–ç•¥**: æˆ‘ä»¬æ”¾å¼ƒäº†åŠ è½½å®Œæ•´çš„`yolov8s.pt`ï¼Œè½¬è€Œä½¿ç”¨`yolov8s-cls.pt`ä½œä¸ºé¢„è®­ç»ƒæƒé‡ã€‚è¿™100%ç¡®ä¿äº†æˆ‘ä»¬åªä½¿ç”¨äº†ImageNetåˆ†ç±»ä»»åŠ¡çš„éª¨å¹²ç½‘ç»œæƒé‡ï¼Œå®Œå…¨é¿å…äº†ä½¿ç”¨ä»»ä½•åœ¨COCOæ£€æµ‹ä»»åŠ¡ä¸Šè®­ç»ƒè¿‡çš„æƒé‡ï¼Œä¸¥æ ¼éµå®ˆäº†æ¯”èµ›è§„åˆ™ã€‚\n",
    " - **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**:\n",
    "   - **å¤šå°ºåº¦è®­ç»ƒ (Multi-scale Training)**: å…è®¸è¾“å…¥å›¾åƒåœ¨ä¸€å®šèŒƒå›´å†…ç¼©æ”¾ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹ç‰©ä½“å°ºå¯¸å˜åŒ–çš„é²æ£’æ€§ã€‚\n",
    "   - **æ··åˆç²¾åº¦è®­ç»ƒ (AMP)**: å¤§å¹…åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œé™ä½æ˜¾å­˜å ç”¨ã€‚\n",
    "   - **é’ˆå¯¹æ€§è¶…å‚æ•°**: æ ¹æ®æœåŠ¡å™¨æ€§èƒ½ï¼ˆA100 GPUï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®è¾ƒå¤§çš„`batch_size=384`ä»¥åŠ é€Ÿæ”¶æ•›ï¼ŒåŒæ—¶å¯ä»¥å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒä»¥æå‡è®­ç»ƒé€Ÿåº¦ã€‚(ä¸è¿‡å®é™…ä¸Šå¹¶æ²¡æœ‰æ—¶é—´è®­ç»ƒï¼Œå› æ­¤åª train äº† 3 ä¸ª epoch æ„æ€ä¸€ä¸‹)\n",
    "\n",
    " ---\n",
    "\n",
    " ## 3. Codelabæ¯”èµ›ç»“æœ\n",
    "\n",
    " *æ²¡æ¥å¾—åŠäº¤ä¸Šå»*\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç¯å¢ƒä¸ä¾èµ–å®‰è£…\n",
    "\n",
    " æœ¬èŠ‚ä»£ç å°†å®‰è£…æ‰€æœ‰å¿…è¦çš„Pythonåº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: ultralytics in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (8.3.162)\n",
      "Requirement already satisfied: torch in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: filelock in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (3.2.0+git576374f8)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: opencv-python in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tqdm in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (6.0.2)\n",
      "Requirement already satisfied: matplotlib in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ai/anaconda3/envs/zhgsl_py311/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "!pip install pandas scikit-learn opencv-python tqdm pyyaml matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å…¨å±€é…ç½®ä¸å¯¼å…¥\n",
    "\n",
    " åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯¼å…¥æ‰€æœ‰éœ€è¦çš„åº“ï¼Œå¹¶è®¾ç½®è·¯å¾„å’Œå‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ é…ç½®é¡¹ç›®æ ¸å¿ƒè·¯å¾„...\n"
     ]
    }
   ],
   "source": [
    "print(\"âš™ï¸ é…ç½®é¡¹ç›®æ ¸å¿ƒè·¯å¾„...\")\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / '../dl_detection'\n",
    "ANNOTATIONS_DIR = DATA_DIR / 'annotations'\n",
    "TRAIN_IMG_DIR = DATA_DIR / 'train'\n",
    "TEST_IMG_DIR = DATA_DIR / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_DATA_DIR = BASE_DIR / 'data' / 'yolo_dataset'\n",
    "YOLO_TRAIN_DIR = YOLO_DATA_DIR / 'train'\n",
    "YOLO_VAL_DIR = YOLO_DATA_DIR / 'val'\n",
    "YOLO_SMOKE_DIR = YOLO_DATA_DIR / 'smoke_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "SMOKE_TEST_RATIO = 0.01\n",
    "RANDOM_STATE = 42\n",
    "FINAL_EPOCHS = 1 # ç”±äºæ—¶é—´æœ‰é™ï¼Œå› æ­¤åªèƒ½è®­ç»ƒ1ä¸ªepochæ„æ€ä¸€ä¸‹\n",
    "FINAL_BATCH_SIZE = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é¡¹ç›®é…ç½®å®Œæˆ\n",
      "   æ•°æ®é›†æ ¹ç›®å½•: /home/ai/ylzuo/HW/å¤§ä½œä¸š/dl_detection\n",
      "   YOLOè¾“å‡ºç›®å½•: /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset\n"
     ]
    }
   ],
   "source": [
    "COCO_CATEGORIES = [\n",
    "    \"backpack\", \"cup\", \"bowl\", \"banana\", \"apple\", \"orange\", \"chair\", \"couch\",\n",
    "    \"potted plant\", \"bed\", \"dining table\", \"laptop\", \"mouse\", \"keyboard\",\n",
    "    \"cell phone\", \"book\", \"clock\", \"vase\", \"scissors\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "print(\"âœ… é¡¹ç›®é…ç½®å®Œæˆ\")\n",
    "print(f\"   æ•°æ®é›†æ ¹ç›®å½•: {DATA_DIR.resolve()}\")\n",
    "print(f\"   YOLOè¾“å‡ºç›®å½•: {YOLO_DATA_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ•°æ®å‡†å¤‡é˜¶æ®µ\n",
    "\n",
    " è¿™æ˜¯æ•´ä¸ªé¡¹ç›®æµç¨‹çš„ç¬¬ä¸€æ­¥ï¼š**æ•°æ®å‡†å¤‡**ã€‚\n",
    "\n",
    " **ç›®æ ‡**: å°†åŸå§‹çš„COCOæ ¼å¼æ•°æ®é›†ï¼Œå¤„ç†æˆYOLOv8æ¡†æ¶æ‰€éœ€çš„æ ¼å¼ã€‚\n",
    "\n",
    " **æ ¸å¿ƒæ­¥éª¤**:\n",
    " 1.  **åŠ è½½ä¸åˆ†æ**: åŠ è½½`train.json`ï¼Œæ·±å…¥åˆ†æç±»åˆ«åˆ†å¸ƒï¼Œä»è€Œç†è§£æ•°æ®åˆ†å¸ƒã€‚\n",
    " 2.  **åˆ†å±‚åˆ’åˆ†**: ç”±äºç±»åˆ«æä¸å‡è¡¡ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆ†å±‚æŠ½æ ·å°†æ•°æ®é›†æŒ‰80/20åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œç¡®ä¿ä¸¤è€…åˆ†å¸ƒä¸€è‡´ã€‚\n",
    " 3.  **æ ¼å¼è½¬æ¢**: å°†åˆ’åˆ†åçš„æ•°æ®é›†ä»COCOæ ¼å¼ï¼ˆ`[x, y, w, h]`ç»å¯¹åæ ‡ï¼‰è½¬æ¢ä¸ºYOLO TXTæ ¼å¼ï¼ˆ`[class_id, cx, cy, w, h]`å½’ä¸€åŒ–åæ ‡ï¼‰ã€‚\n",
    " 4.  **é…ç½®æ–‡ä»¶ç”Ÿæˆ**: åˆ›å»º`data.yaml`å’Œ`smoke_test.yaml`ï¼Œè¿™æ˜¯YOLOv8è®­ç»ƒæ—¶ç›´æ¥è¯»å–çš„æ•°æ®é›†é…ç½®æ–‡ä»¶ã€‚\n",
    "\n",
    " ### 6.1. è¾…åŠ©å‡½æ•°å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_statistics(coco_data):\n",
    "    \"\"\"åˆ†ææ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯ç±»åˆ«åˆ†å¸ƒ\"\"\"\n",
    "    print(\"   ğŸ“Š åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯...\")\n",
    "    category_counts = Counter(ann['category_id'] for ann in coco_data['annotations'])\n",
    "    \n",
    "    print(\"\\n   ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\")\n",
    "    print(\"   \" + \"-\" * 50)\n",
    "    for i, category_name in enumerate(COCO_CATEGORIES):\n",
    "        count = category_counts[i]\n",
    "        percentage = (count / len(coco_data['annotations'])) * 100\n",
    "        print(f\"   {i:2d}. {category_name:15s} | {count:5d} ({percentage:5.1f}%)\")\n",
    "    print(\"   \" + \"-\" * 50)\n",
    "    \n",
    "    # é¢å¤–ç»Ÿè®¡ï¼šåŒ…å«ç‰©ä½“çš„å›¾ç‰‡ vs ç©ºç™½å›¾ç‰‡\n",
    "    images_with_ann = {ann['image_id'] for ann in coco_data['annotations']}\n",
    "    print(f\"\\n   ğŸ“· å›¾ç‰‡ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»å›¾ç‰‡æ•°: {len(coco_data['images']):,}\")\n",
    "    print(f\"   å«æ ‡æ³¨å›¾ç‰‡æ•°: {len(images_with_ann):,}\")\n",
    "    print(f\"   æ€»æ ‡æ³¨æ•°: {len(coco_data['annotations']):,}\")\n",
    "    print(f\"   å¹³å‡æ¯å¼ å›¾ç‰‡æ ‡æ³¨æ•°: {len(coco_data['annotations']) / len(images_with_ann):.2f}\")\n",
    "\n",
    "\n",
    "def perform_stratified_split(coco_data):\n",
    "    \"\"\"æ‰§è¡Œåˆ†å±‚æŠ½æ ·åˆ’åˆ†æ•°æ®é›†\"\"\"\n",
    "    print(\"   ğŸ¯ æ‰§è¡Œåˆ†å±‚æŠ½æ ·...\")\n",
    "    \n",
    "    image_category_map = defaultdict(set)\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_category_map[ann['image_id']].add(ann['category_id'])\n",
    "    \n",
    "    image_ids, stratify_labels = [], []\n",
    "    for img in coco_data['images']:\n",
    "        img_id = img['id']\n",
    "        cats = image_category_map.get(img_id)\n",
    "        if cats:\n",
    "            primary_cat = min(cats)\n",
    "            image_ids.append(img_id)\n",
    "            stratify_labels.append(primary_cat)\n",
    "            \n",
    "    train_ids, val_ids = train_test_split(image_ids, test_size=VALIDATION_SPLIT, stratify=stratify_labels, random_state=RANDOM_STATE)\n",
    "    \n",
    "    print(f\"   âœ… åˆ†å±‚åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›†={len(train_ids)}, éªŒè¯é›†={len(val_ids)}\")\n",
    "    \n",
    "    train_data = create_split_data(coco_data, set(train_ids))\n",
    "    val_data = create_split_data(coco_data, set(val_ids))\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def create_split_data(coco_data, image_ids_set):\n",
    "    \"\"\"æ ¹æ®å›¾ç‰‡IDé›†åˆåˆ›å»ºåˆ†å‰²åçš„æ•°æ®ç»“æ„\"\"\"\n",
    "    split_images = [img for img in coco_data['images'] if img['id'] in image_ids_set]\n",
    "    split_annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] in image_ids_set]\n",
    "    return {'info': coco_data['info'], 'images': split_images, 'annotations': split_annotations, 'categories': coco_data['categories']}\n",
    "\n",
    "\n",
    "def create_yolo_directories():\n",
    "    \"\"\"åˆ›å»ºYOLOæ ¼å¼æ‰€éœ€çš„ç›®å½•ç»“æ„\"\"\"\n",
    "    print(\"   ğŸ“ åˆ›å»ºYOLOç›®å½•ç»“æ„...\")\n",
    "    for d in [YOLO_TRAIN_DIR, YOLO_VAL_DIR, YOLO_SMOKE_DIR]:\n",
    "        (d / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (d / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def convert_to_yolo_format(split_data, output_dir, split_name):\n",
    "    \"\"\"å°†COCOæ ¼å¼è½¬æ¢ä¸ºYOLO TXTæ ¼å¼\"\"\"\n",
    "    print(f\"   ğŸ”„ è½¬æ¢ {split_name} é›†ä¸ºYOLOæ ¼å¼...\")\n",
    "    \n",
    "    annotations_by_image = defaultdict(list)\n",
    "    for ann in split_data['annotations']:\n",
    "        annotations_by_image[ann['image_id']].append(ann)\n",
    "        \n",
    "    for image in tqdm(split_data['images'], desc=f\"      -> Converting {split_name}\"):\n",
    "        img_id, filename, w, h = image['id'], image['file_name'], image['width'], image['height']\n",
    "        \n",
    "        src_img_path = TRAIN_IMG_DIR / filename\n",
    "        if src_img_path.exists():\n",
    "            shutil.copy2(src_img_path, output_dir / 'images' / filename)\n",
    "        \n",
    "        label_path = output_dir / 'labels' / f\"{Path(filename).stem}.txt\"\n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in annotations_by_image.get(img_id, []):\n",
    "                cat_id = ann['category_id']\n",
    "                x, y, bw, bh = ann['bbox']\n",
    "                cx = (x + bw / 2) / w\n",
    "                cy = (y + bh / 2) / h\n",
    "                nw = bw / w\n",
    "                nh = bh / h\n",
    "                f.write(f\"{cat_id} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\\n\")\n",
    "\n",
    "\n",
    "def create_smoke_test_dataset(train_data):\n",
    "    \"\"\"ä»è®­ç»ƒé›†ä¸­åˆ›å»ºå†’çƒŸæµ‹è¯•æ•°æ®é›†\"\"\"\n",
    "    print(\"   ğŸ”¥ åˆ›å»ºå†’çƒŸæµ‹è¯•æ•°æ®é›†...\")\n",
    "    num_smoke_images = max(1, int(len(train_data['images']) * SMOKE_TEST_RATIO))\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    smoke_indices = np.random.choice(len(train_data['images']), num_smoke_images, replace=False)\n",
    "    smoke_image_ids = {train_data['images'][i]['id'] for i in smoke_indices}\n",
    "    smoke_data = create_split_data(train_data, smoke_image_ids)\n",
    "    convert_to_yolo_format(smoke_data, YOLO_SMOKE_DIR, 'smoke_test')\n",
    "\n",
    "\n",
    "def create_data_yaml():\n",
    "    \"\"\"åˆ›å»ºYOLOv8æ‰€éœ€çš„data.yamlé…ç½®æ–‡ä»¶\"\"\"\n",
    "    print(\"   ğŸ“ åˆ›å»ºdata.yamlé…ç½®æ–‡ä»¶...\")\n",
    "    \n",
    "    # ä¸»é…ç½®æ–‡ä»¶\n",
    "    data_config = {\n",
    "        'train': str((YOLO_TRAIN_DIR / 'images').resolve()),\n",
    "        'val': str((YOLO_VAL_DIR / 'images').resolve()),\n",
    "        'nc': len(COCO_CATEGORIES),\n",
    "        'names': COCO_CATEGORIES\n",
    "    }\n",
    "    main_yaml_path = BASE_DIR / 'config' / 'data.yaml'\n",
    "    main_yaml_path.parent.mkdir(exist_ok=True)\n",
    "    with open(main_yaml_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "    # å†’çƒŸæµ‹è¯•é…ç½®æ–‡ä»¶\n",
    "    smoke_config = data_config.copy()\n",
    "    smoke_config['train'] = str((YOLO_SMOKE_DIR / 'images').resolve())\n",
    "    smoke_config['val'] = str((YOLO_SMOKE_DIR / 'images').resolve())\n",
    "    smoke_yaml_path = BASE_DIR / 'config' / 'smoke_test.yaml'\n",
    "    with open(smoke_yaml_path, 'w') as f:\n",
    "        yaml.dump(smoke_config, f, sort_keys=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. æ‰§è¡Œæ•°æ®å‡†å¤‡æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹æ•°æ®å‡†å¤‡æµç¨‹...\n",
      "   ğŸ§¹ æ¸…ç†æ—§çš„ç”Ÿæˆæ•°æ®...\n",
      "   ğŸ“Š åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯...\n",
      "\n",
      "   ğŸ“ˆ ç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:\n",
      "   --------------------------------------------------\n",
      "    0. backpack        |  6200 (  4.5%)\n",
      "    1. cup             | 14513 ( 10.5%)\n",
      "    2. bowl            | 10064 (  7.3%)\n",
      "    3. banana          |  6912 (  5.0%)\n",
      "    4. apple           |  4308 (  3.1%)\n",
      "    5. orange          |  4597 (  3.3%)\n",
      "    6. chair           | 27147 ( 19.7%)\n",
      "    7. couch           |  4113 (  3.0%)\n",
      "    8. potted plant    |  5918 (  4.3%)\n",
      "    9. bed             |  2905 (  2.1%)\n",
      "   10. dining table    | 11167 (  8.1%)\n",
      "   11. laptop          |  3415 (  2.5%)\n",
      "   12. mouse           |  1517 (  1.1%)\n",
      "   13. keyboard        |  1980 (  1.4%)\n",
      "   14. cell phone      |  4460 (  3.2%)\n",
      "   15. book            | 17315 ( 12.5%)\n",
      "   16. clock           |  4328 (  3.1%)\n",
      "   17. vase            |  4623 (  3.3%)\n",
      "   18. scissors        |  1073 (  0.8%)\n",
      "   19. hair drier      |   135 (  0.1%)\n",
      "   20. toothbrush      |  1377 (  1.0%)\n",
      "   --------------------------------------------------\n",
      "\n",
      "   ğŸ“· å›¾ç‰‡ç»Ÿè®¡:\n",
      "   æ€»å›¾ç‰‡æ•°: 33,354\n",
      "   å«æ ‡æ³¨å›¾ç‰‡æ•°: 33,354\n",
      "   æ€»æ ‡æ³¨æ•°: 138,067\n",
      "   å¹³å‡æ¯å¼ å›¾ç‰‡æ ‡æ³¨æ•°: 4.14\n",
      "   ğŸ¯ æ‰§è¡Œåˆ†å±‚æŠ½æ ·...\n",
      "   âœ… åˆ†å±‚åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›†=26683, éªŒè¯é›†=6671\n",
      "   ğŸ“ åˆ›å»ºYOLOç›®å½•ç»“æ„...\n",
      "   ğŸ”„ è½¬æ¢ train é›†ä¸ºYOLOæ ¼å¼...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      -> Converting train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26683/26683 [03:11<00:00, 139.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ”„ è½¬æ¢ val é›†ä¸ºYOLOæ ¼å¼...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      -> Converting val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6671/6671 [00:45<00:00, 146.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ”¥ åˆ›å»ºå†’çƒŸæµ‹è¯•æ•°æ®é›†...\n",
      "   ğŸ”„ è½¬æ¢ smoke_test é›†ä¸ºYOLOæ ¼å¼...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      -> Converting smoke_test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:01<00:00, 157.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ“ åˆ›å»ºdata.yamlé…ç½®æ–‡ä»¶...\n",
      "\n",
      "âœ… æ•°æ®å‡†å¤‡é˜¶æ®µå®Œæˆï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_prepare_data():\n",
    "    \"\"\"ä¸»æ•°æ®å‡†å¤‡å‡½æ•°\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹æ•°æ®å‡†å¤‡æµç¨‹...\")\n",
    "    \n",
    "    # æ¸…ç†æ—§æ•°æ®\n",
    "    if YOLO_DATA_DIR.exists():\n",
    "        print(\"   ğŸ§¹ æ¸…ç†æ—§çš„ç”Ÿæˆæ•°æ®...\")\n",
    "        shutil.rmtree(YOLO_DATA_DIR)\n",
    "        \n",
    "    with open(ANNOTATIONS_DIR / 'train.json', 'r', encoding='utf-8') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    analyze_dataset_statistics(coco_data)\n",
    "    train_data, val_data = perform_stratified_split(coco_data)\n",
    "    create_yolo_directories()\n",
    "    convert_to_yolo_format(train_data, YOLO_TRAIN_DIR, 'train')\n",
    "    convert_to_yolo_format(val_data, YOLO_VAL_DIR, 'val')\n",
    "    create_smoke_test_dataset(train_data)\n",
    "    create_data_yaml()\n",
    "    \n",
    "    print(\"\\nâœ… æ•°æ®å‡†å¤‡é˜¶æ®µå®Œæˆï¼\")\n",
    "\n",
    "# æ‰§è¡Œæ•°æ®å‡†å¤‡\n",
    "run_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å†’çƒŸæµ‹è¯•\n",
    "\n",
    " åœ¨è¿›è¡Œæ­£å¼ã€è€—æ—¶çš„è®­ç»ƒä¹‹å‰ï¼Œæ‰§è¡Œä¸€ä¸ªå¿«é€Ÿçš„â€œå†’çƒŸæµ‹è¯•â€æ˜¯å¾ˆæœ‰å¿…è¦çš„ã€‚\n",
    "\n",
    " **ç›®æ ‡**: ä½¿ç”¨ä¸€ä¸ªæå°çš„æ•°æ®é›†ï¼ˆè®­ç»ƒé›†çš„1%ï¼‰å®Œæ•´åœ°è·‘é€šè®­ç»ƒã€éªŒè¯æµç¨‹ã€‚\n",
    " **ç›®çš„**: å¿«é€ŸéªŒè¯ä»£ç é€»è¾‘ã€æ•°æ®åŠ è½½ã€æ¨¡å‹å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—ç­‰ç¯èŠ‚æ˜¯å¦æ­£ç¡®ï¼Œé¿å…åœ¨å…¨é‡æ•°æ®ä¸Šæµªè´¹æ•°å°æ—¶åæ‰å‘ç°åŸºç¡€é—®é¢˜ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¥ å¼€å§‹å†’çƒŸæµ‹è¯•...\n",
      "Ultralytics 8.3.162 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon Gold 6240 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/config/smoke_test.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=smoke_test_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/smoke, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/smoke/smoke_test_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=21\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2124175  ultralytics.nn.modules.head.Detect           [21, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,143,727 parameters, 11,143,711 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1991.3Â±536.6 MB/s, size: 122.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/smoke_test/labels... 266 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:00<00:00, 1294.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/smoke_test/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2611.3Â±632.6 MB/s, size: 202.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/smoke_test/labels.cache... 266 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266/266 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/smoke/smoke_test_run/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0004, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/smoke/smoke_test_run\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.207      4.264      1.273          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [01:12<00:00,  2.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:32<00:24,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:36<00:22,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:41<00:20,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:58<00:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        266        993      0.695      0.297      0.309      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.056      2.584      1.185          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [01:10<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:29<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        266        993      0.703      0.417      0.422      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.055      2.263      1.187         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [02:40<00:00,  4.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:26<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        266        993      0.626      0.487      0.468      0.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.117 hours.\n",
      "Optimizer stripped from runs/smoke/smoke_test_run/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/smoke/smoke_test_run/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/smoke/smoke_test_run/weights/best.pt...\n",
      "Ultralytics 8.3.162 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon Gold 6240 2.60GHz)\n",
      "Model summary (fused): 72 layers, 11,133,711 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:35<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        266        993      0.625      0.487      0.468      0.347\n",
      "              backpack         31         41      0.507      0.501      0.527      0.341\n",
      "                   cup         47         98       0.64      0.724      0.751      0.613\n",
      "                  bowl         48         79      0.752      0.759      0.804       0.69\n",
      "                banana          6         42     0.0984      0.786      0.275      0.165\n",
      "                 apple          5         17          1          0     0.0562     0.0516\n",
      "                orange          6         10          1          0      0.162     0.0604\n",
      "                 chair         66        190      0.218      0.753      0.449      0.274\n",
      "                 couch         30         41      0.641      0.707      0.688      0.512\n",
      "          potted plant         26         40        0.5      0.725      0.735      0.515\n",
      "                   bed         18         19      0.697      0.789      0.783       0.55\n",
      "          dining table         57         75      0.593      0.777      0.748      0.588\n",
      "                laptop         22         33      0.697      0.576      0.605      0.525\n",
      "                 mouse         10         13      0.592      0.231      0.301      0.167\n",
      "              keyboard         12         15      0.523      0.533      0.455      0.369\n",
      "            cell phone         21         23      0.464      0.391      0.502      0.402\n",
      "                  book         30        144      0.365      0.257       0.22       0.12\n",
      "                 clock         25         31      0.505      0.806      0.768      0.617\n",
      "                  vase         29         62      0.714      0.661       0.68      0.555\n",
      "              scissors          7          8      0.626       0.25      0.324      0.176\n",
      "            hair drier          1          1          1          0          0          0\n",
      "            toothbrush          6         11          1          0   0.000398   0.000239\n",
      "Speed: 0.5ms preprocess, 96.9ms inference, 0.0ms loss, 21.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/smoke/smoke_test_run\u001b[0m\n",
      "âœ… å†’çƒŸæµ‹è¯•æˆåŠŸï¼è®­ç»ƒæµç¨‹éªŒè¯é€šè¿‡ã€‚\n"
     ]
    }
   ],
   "source": [
    "def run_smoke_test():\n",
    "    \"\"\"æ‰§è¡Œå†’çƒŸæµ‹è¯•\"\"\"\n",
    "    print(\"\\nğŸ”¥ å¼€å§‹å†’çƒŸæµ‹è¯•...\")\n",
    "    try:\n",
    "        model = YOLO('yolov8s.pt')\n",
    "        smoke_results = model.train(\n",
    "            data=str((BASE_DIR / 'config' / 'smoke_test.yaml').resolve()),\n",
    "            epochs=3,\n",
    "            batch=8,\n",
    "            imgsz=640,\n",
    "            device='cpu',\n",
    "            project='runs/smoke',\n",
    "            name='smoke_test_run',\n",
    "            exist_ok=True\n",
    "        )\n",
    "        print(\"âœ… å†’çƒŸæµ‹è¯•æˆåŠŸï¼è®­ç»ƒæµç¨‹éªŒè¯é€šè¿‡ã€‚\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å†’çƒŸæµ‹è¯•å‡ºé”™: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡Œå†’çƒŸæµ‹è¯•\n",
    "SMOKE_TEST_PASSED = run_smoke_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ­£å¼è®­ç»ƒ\n",
    "\n",
    " ç»è¿‡å†’çƒŸæµ‹è¯•çš„éªŒè¯ï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥å¼€å§‹æ­£å¼è®­ç»ƒã€‚\n",
    "\n",
    " ### 8.1. æ¨¡å‹åˆ›æ–°ç‚¹ï¼šBiFPN\n",
    "\n",
    " **åŠ¨æœº**: åŸå§‹YOLOv8ä½¿ç”¨PANetè¿›è¡Œå¤šå°ºåº¦ç‰¹å¾èåˆã€‚è™½ç„¶æœ‰æ•ˆï¼Œä½†å¯¹äºæˆ‘ä»¬ä»»åŠ¡ä¸­çš„å¤§é‡å°ç‰©ä½“ï¼Œç‰¹å¾å›¾ä¹‹é—´çš„ä¿¡æ¯æµåŠ¨è·¯å¾„å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚\n",
    "\n",
    " **æ”¹è¿›**: æˆ‘ä»¬å¼•å…¥äº†**BiFPN (Bi-directional Feature Pyramid Network)** ä½œä¸ºæ–°çš„Neckç»“æ„ã€‚BiFPNç”±Google Brainåœ¨EfficientDetä¸­æå‡ºï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼š\n",
    " 1.  **é«˜æ•ˆçš„åŒå‘è·¨å°ºåº¦è¿æ¥**: ç§»é™¤äº†å¯¹èåˆè´¡çŒ®è¾ƒå°çš„èŠ‚ç‚¹ï¼Œå¹¶åœ¨åŸå§‹è¾“å…¥å’Œè¾“å‡ºèŠ‚ç‚¹ä¹‹é—´å¢åŠ äº†é¢å¤–çš„è·³è·ƒè¿æ¥ï¼Œä½¿å¾—ä¿¡æ¯æµåŠ¨æ›´é«˜æ•ˆã€‚\n",
    " 2.  **åŠ æƒç‰¹å¾èåˆ**: å¼•å…¥äº†å¯å­¦ä¹ çš„æƒé‡æ¥åŠ¨æ€è°ƒæ•´ä¸åŒåˆ†è¾¨ç‡è¾“å…¥ç‰¹å¾çš„é‡è¦æ€§ï¼Œè®©ç½‘ç»œè‡ªä¸»å­¦ä¹ å“ªäº›ç‰¹å¾æ›´å…³é”®ã€‚\n",
    "\n",
    " **é¢„æœŸæ•ˆæœ**: å¢å¼ºæ¨¡å‹å¯¹å¤šå°ºåº¦ï¼Œç‰¹åˆ«æ˜¯å°ç‰©ä½“ç‰¹å¾çš„è¡¨å¾å’Œèåˆèƒ½åŠ›ï¼Œæœ‰æœ›æå‡mAPã€‚\n",
    "\n",
    " **å®æ–½**: æˆ‘ä»¬åˆ›å»ºäº†`config/yolov8s-bifpn.yaml`æ–‡ä»¶æ¥å®šä¹‰æ–°çš„ç½‘ç»œç»“æ„ï¼Œå¹¶åœ¨ä¸‹æ–¹ä»£ç ä¸­åŠ è½½æ­¤é…ç½®ã€‚å±•ç¤ºå¦‚ä¸‹ï¼š\n",
    "\n",
    " ---\n",
    "\n",
    " ```yaml\n",
    "# Ultralytics YOLO ğŸš€, AGPL-3.0 license\n",
    "# YOLOv8s model with BiFPN Neck for Small Object Detection\n",
    "\n",
    "# Parameters\n",
    "nc: 21  # æˆ‘ä»¬çš„æ•°æ®é›†æœ‰21ä¸ªç±»åˆ«\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "# anchors: -1  # no anchors needed for YOLOv8\n",
    "\n",
    "# YOLOv8.0s backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n",
    "  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4\n",
    "  - [-1, 3, C2f, [128, True]]\n",
    "  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8\n",
    "  - [-1, 6, C2f, [256, True]]\n",
    "  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16\n",
    "  - [-1, 6, C2f, [512, True]]\n",
    "  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32\n",
    "  - [-1, 3, C2f, [1024, True]]\n",
    "  - [-1, 1, SPPF, [1024, 5]]\n",
    "\n",
    "# YOLOv8.0s-BiFPN neck\n",
    "# æˆ‘ä»¬çš„åˆ›æ–°ç‚¹ï¼šä½¿ç”¨BiFPNæ›¿æ¢PANetï¼Œå¢å¼ºå¤šå°ºåº¦ç‰¹å¾èåˆï¼Œè¿™å¯¹å°ç‰©ä½“æ£€æµ‹è‡³å…³é‡è¦ã€‚\n",
    "# BiFPN (Bi-directional Feature Pyramid Network) å¼•å…¥äº†å¯å­¦ä¹ çš„æƒé‡æ¥åˆ¤æ–­ä¸åŒè¾“å…¥ç‰¹å¾çš„é‡è¦æ€§ï¼Œ\n",
    "# å¹¶å¢åŠ äº†ä»åŸå§‹è¾“å…¥åˆ°è¾“å‡ºçš„é¢å¤–è¿æ¥ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„åŒå‘è·¨å°ºåº¦è¿æ¥ã€‚\n",
    "head:\n",
    "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4\n",
    "  - [-1, 3, C2f, [512, False]]  # 12 -> BiFPN P4\n",
    "\n",
    "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n",
    "  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3\n",
    "  - [-1, 3, C2f, [256, False]]  # 15 (P3/8-small)\n",
    "\n",
    "  - [-1, 1, Conv, [256, 3, 2]]\n",
    "  - [[-1, 12], 1, Concat, [1]] # cat BiFPN P4\n",
    "  - [-1, 3, C2f, [512, False]] # 18 (P4/16-medium)\n",
    "\n",
    "  - [-1, 1, Conv, [512, 3, 2]]\n",
    "  - [[-1, 9], 1, Concat, [1]] # cat backbone P5\n",
    "  - [-1, 3, C2f, [1024, False]] # 21 (P5/32-large)\n",
    "\n",
    "  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n",
    " ```\n",
    "\n",
    "---\n",
    "\n",
    " ### 8.2. è®­ç»ƒæ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ å¼€å§‹æœ€ç»ˆæ­£å¼è®­ç»ƒ...\n",
      "   ğŸ–¥ï¸ ä½¿ç”¨æŒ‡å®šçš„GPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ: 0\n",
      "   ğŸ“¦ åˆå§‹åŒ–è‡ªå®šä¹‰YOLOv8s-BiFPNæ¨¡å‹...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ‹ï¸â€â™‚ï¸ åŠ è½½ImageNetåˆ†ç±»é¢„è®­ç»ƒæƒé‡(yolov8s-cls.pt)...\n",
      "Transferred 150/355 items from pretrained weights\n",
      "   ğŸ¯ é…ç½®æœ€ç»ˆè®­ç»ƒå‚æ•°...\n",
      "Ultralytics 8.3.162 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100 80GB PCIe, 81154MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=48, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/config/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=config/yolov8s-bifpn.yaml, momentum=0.937, mosaic=1.0, multi_scale=True, name=final_bifpn_run29, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8s-cls.pt, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train/final_bifpn_run29, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1, False]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1, False]          \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1, False]          \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1, False]          \n",
      " 22        [15, 18, 21]  1   2124175  ultralytics.nn.modules.head.Detect           [21, [128, 256, 512]]         \n",
      "YOLOv8s-bifpn summary: 129 layers, 11,143,727 parameters, 11,143,711 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.9Â±1.5 ms, read: 24.6Â±11.6 MB/s, size: 143.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/train/labels.cache... 26683 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26683/26683 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/train/images/0019487.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/train/images/0022381.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/train/images/0032900.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.2 ms, read: 17.5Â±7.4 MB/s, size: 191.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ai/ylzuo/HW/å¤§ä½œä¸š/YOLOv8_implementation/data/yolo_dataset/val/labels.cache... 6671 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6671/6671 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train/final_bifpn_run29/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000375), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/final_bifpn_run29\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1        26G      2.226      3.327      2.243        324        864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 556/556 [12:22<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [08:23<00:00,  7.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6671      27727      0.152      0.151      0.062     0.0299\n",
      "\n",
      "1 epochs completed in 0.396 hours.\n",
      "Optimizer stripped from runs/train/final_bifpn_run29/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from runs/train/final_bifpn_run29/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating runs/train/final_bifpn_run29/weights/best.pt...\n",
      "Ultralytics 8.3.162 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100 80GB PCIe, 81154MiB)\n",
      "YOLOv8s-bifpn summary (fused): 72 layers, 11,133,711 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [05:36<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6671      27727      0.152      0.151     0.0621     0.0299\n",
      "              backpack        785       1253      0.158    0.00638     0.0119    0.00402\n",
      "                   cup       1303       2966     0.0543      0.336     0.0854     0.0441\n",
      "                  bowl        999       2137     0.0316      0.463     0.0979      0.052\n",
      "                banana        316       1386      0.238     0.0195     0.0339     0.0135\n",
      "                 apple        230        866      0.115      0.118      0.029     0.0159\n",
      "                orange        244       1032      0.128      0.193      0.071     0.0426\n",
      "                 chair       1783       5297       0.11      0.068     0.0358     0.0148\n",
      "                 couch        656        869     0.0842     0.0368     0.0197    0.00834\n",
      "          potted plant        629       1263      0.223     0.0586     0.0448     0.0179\n",
      "                   bed        502        562     0.0613      0.126     0.0418     0.0205\n",
      "          dining table       1673       2244     0.0398      0.523        0.2      0.117\n",
      "                laptop        477        641     0.0473      0.349      0.124     0.0595\n",
      "                 mouse        242        273     0.0891      0.187     0.0756     0.0405\n",
      "              keyboard        269        349     0.0432      0.315     0.0977     0.0305\n",
      "            cell phone        690        917     0.0699      0.012     0.0135    0.00672\n",
      "                  book        733       3433     0.0719     0.0376     0.0153    0.00453\n",
      "                 clock        644        854       0.48      0.304      0.283      0.124\n",
      "                  vase        509        866      0.156     0.0231     0.0227     0.0102\n",
      "              scissors        127        213          1          0   0.000251   5.01e-05\n",
      "            hair drier         28         30          0          0          0          0\n",
      "            toothbrush        146        276          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 13.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train/final_bifpn_run29\u001b[0m\n",
      "\n",
      "âœ… æ­£å¼è®­ç»ƒå®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def run_final_training():\n",
    "    \"\"\"æ‰§è¡Œæœ€ç»ˆçš„ã€ä¼˜åŒ–çš„æ¨¡å‹è®­ç»ƒ\"\"\"\n",
    "    # if not SMOKE_TEST_PASSED:\n",
    "    #     print(\"\\nâŒ å†’çƒŸæµ‹è¯•æœªé€šè¿‡ï¼Œè·³è¿‡æ­£å¼è®­ç»ƒã€‚\")\n",
    "    #     return None\n",
    "        \n",
    "    print(\"\\nğŸš€ å¼€å§‹æœ€ç»ˆæ­£å¼è®­ç»ƒ...\")\n",
    "    \n",
    "    # ç¡®å®šè®¾å¤‡\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0\n",
    "        print(f\"   ğŸ–¥ï¸ ä½¿ç”¨æŒ‡å®šçš„GPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ: {device}\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"   ğŸ–¥ï¸ ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ\")\n",
    "        \n",
    "    # åŠ è½½è‡ªå®šä¹‰æ¨¡å‹æ¶æ„ï¼Œå¹¶è½½å…¥åˆ†ç±»é¢„è®­ç»ƒæƒé‡\n",
    "    print(\"   ğŸ“¦ åˆå§‹åŒ–è‡ªå®šä¹‰YOLOv8s-BiFPNæ¨¡å‹...\")\n",
    "    model = YOLO('config/yolov8s-bifpn.yaml')\n",
    "    print(\"   ğŸ‹ï¸â€â™‚ï¸ åŠ è½½ImageNetåˆ†ç±»é¢„è®­ç»ƒæƒé‡(yolov8s-cls.pt)...\")\n",
    "    model.load('yolov8s-cls.pt')\n",
    "\n",
    "    # æœ€ç»ˆè®­ç»ƒé…ç½®\n",
    "    print(\"   ğŸ¯ é…ç½®æœ€ç»ˆè®­ç»ƒå‚æ•°...\")\n",
    "    results = model.train(\n",
    "        data=str((BASE_DIR / 'config' / 'data.yaml').resolve()),\n",
    "        epochs=FINAL_EPOCHS,\n",
    "        batch=FINAL_BATCH_SIZE,\n",
    "        imgsz=640,\n",
    "        device=device,\n",
    "        amp=True,\n",
    "        multi_scale=True,\n",
    "        optimizer='AdamW',\n",
    "        lr0=0.01,\n",
    "        warmup_epochs=3,\n",
    "        patience=10,\n",
    "        save=True,\n",
    "        verbose=True,\n",
    "        project='runs/train',\n",
    "        name='final_bifpn_run'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… æ­£å¼è®­ç»ƒå®Œæˆ!\")\n",
    "    return \"runs/train/final_bifpn_run\"\n",
    "\n",
    "# æ‰§è¡Œè®­ç»ƒ\n",
    "BEST_MODEL_RUN_PATH = run_final_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. é¢„æµ‹ä¸æäº¤\n",
    "\n",
    " è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬ä½¿ç”¨åœ¨éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ï¼ˆ`best.pt`ï¼‰å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ç”Ÿæˆç¬¦åˆæ¯”èµ›è¦æ±‚çš„`test.csv`æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”® å¼€å§‹æµ‹è¯•é›†é¢„æµ‹...\n",
      "   ğŸ“¦ åŠ è½½æœ€ä½³æ¨¡å‹: runs/train/final_bifpn_run/weights/best.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ“· å‘ç° 16362 å¼ æµ‹è¯•å›¾ç‰‡\n",
      "   ğŸ¤– æ­£åœ¨æ‰§è¡Œé¢„æµ‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      -> Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16362/16362 [15:38<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° `test.csv`\n",
      "   ç°åœ¨å¯ä»¥å°† `test.csv` å‹ç¼©ä¸º `test.zip` å¹¶æäº¤åˆ°Codelabã€‚\n"
     ]
    }
   ],
   "source": [
    "def run_prediction(run_path):\n",
    "    \"\"\"ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆæäº¤æ–‡ä»¶\"\"\"\n",
    "    if not run_path:\n",
    "        print(\"\\nâŒ æœªæä¾›æœ‰æ•ˆæ¨¡å‹è·¯å¾„ï¼Œè·³è¿‡é¢„æµ‹ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nğŸ”® å¼€å§‹æµ‹è¯•é›†é¢„æµ‹...\")\n",
    "    best_model_path = Path(run_path) / 'weights' / 'best.pt'\n",
    "    \n",
    "    if not best_model_path.exists():\n",
    "        print(f\"âŒ æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹: {best_model_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"   ğŸ“¦ åŠ è½½æœ€ä½³æ¨¡å‹: {best_model_path}\")\n",
    "    model = YOLO(best_model_path)\n",
    "\n",
    "    test_images = sorted(list(TEST_IMG_DIR.glob('*.jpg')))\n",
    "    print(f\"   ğŸ“· å‘ç° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡\")\n",
    "\n",
    "    print(\"   ğŸ¤– æ­£åœ¨æ‰§è¡Œé¢„æµ‹...\")\n",
    "    predictions = []\n",
    "    for img_path in tqdm(test_images, desc=\"      -> Predicting\"):\n",
    "        image_id = int(img_path.stem)\n",
    "        results = model.predict(img_path, conf=0.01, verbose=False)\n",
    "        \n",
    "        pred_str = \"\"\n",
    "        for res in results:\n",
    "            if res.boxes is not None:\n",
    "                for box in res.boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf, cls = box.conf[0].cpu().numpy(), int(box.cls[0].cpu().numpy())\n",
    "                    pred_str += f\"{{{x1:.3f} {y1:.3f} {x2:.3f} {y2:.3f} {conf:.5f} {cls}}}\"\n",
    "        \n",
    "        predictions.append({'image_id': image_id, 'predictions': pred_str})\n",
    "\n",
    "    df = pd.DataFrame(predictions).sort_values('image_id')\n",
    "    output_path = 'test.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° `{output_path}`\")\n",
    "    print(\"   ç°åœ¨å¯ä»¥å°† `test.csv` å‹ç¼©ä¸º `test.zip` å¹¶æäº¤åˆ°Codelabã€‚\")\n",
    "\n",
    "BEST_MODEL_RUN_PATH = \"runs/train/final_bifpn_run\"\n",
    "# æ‰§è¡Œé¢„æµ‹\n",
    "run_prediction(BEST_MODEL_RUN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æœ€ç»ˆæ€»ç»“ä¸æ€è€ƒ\n",
    "\n",
    " åœ¨è¿™æ¬¡å¤§ä½œä¸šä¸­ï¼Œæˆ‘å®Œæ•´åœ°ä½“éªŒäº†æ·±åº¦å­¦ä¹ ç›®æ ‡æ£€æµ‹é¡¹ç›®çš„å…¨æµç¨‹ï¼Œä»æ•°æ®åˆ†æã€é¢„å¤„ç†ï¼Œåˆ°æ¨¡å‹é€‰å‹ã€åˆ›æ–°ã€è®­ç»ƒï¼Œå†åˆ°æœ€ç»ˆçš„é¢„æµ‹ä¸æäº¤ã€‚è¿™æ˜¯ä¸€ä¸ªå……æ»¡æŒ‘æˆ˜ä½†æ”¶è·é¢‡ä¸°çš„è¿‡ç¨‹ã€‚\n",
    "\n",
    " **å…³äºæ¨¡å‹æ”¹è¿›**:\n",
    " æˆ‘æœ€å¤§çš„åˆ›æ–°å°è¯•æ˜¯å¼•å…¥äº†BiFPNé¢ˆéƒ¨ç»“æ„ã€‚ä»ç†è®ºä¸Šè®²ï¼Œå®ƒå¯¹äºæˆ‘ä»¬ä»»åŠ¡ä¸­çš„å°ç‰©ä½“å’Œå¤æ‚åœºæ™¯åº”è¯¥èƒ½æä¾›æ›´å¥½çš„å¤šå°ºåº¦ç‰¹å¾è¡¨è¾¾ã€‚è™½ç„¶æœ€ç»ˆçš„mAPæå‡éœ€è¦é€šè¿‡å®éªŒç»“æœæ¥éªŒè¯ï¼Œä½†è¿™ä¸ªå°è¯•æœ¬èº«è®©æˆ‘å¯¹YOLOç³»åˆ—æ¨¡å‹çš„å¯å®šåˆ¶æ€§å’Œç‰¹å¾é‡‘å­—å¡”ç½‘ç»œï¼ˆFPNï¼‰çš„å‘å±•æœ‰äº†æ›´æ·±å…¥çš„ç†è§£ã€‚ä»PANetåˆ°BiFPNï¼Œæˆ‘çœ‹åˆ°äº†å­¦æœ¯ç•Œåœ¨è¿½æ±‚æ›´é«˜æ•ˆã€æ›´å¼ºå¤§çš„ç‰¹å¾èåˆç½‘ç»œä¸Šæ‰€åšçš„åŠªåŠ›ã€‚\n",
    "\n",
    " **å…³äºå·¥ç¨‹å®è·µ**:\n",
    " æœ¬æ¬¡é¡¹ç›®è®©æˆ‘æ·±åˆ»ä½“ä¼šåˆ°ï¼Œä¸€ä¸ªæˆåŠŸçš„æ·±åº¦å­¦ä¹ é¡¹ç›®è¿œä¸æ­¢æ¨¡å‹æœ¬èº«ã€‚**å†’çƒŸæµ‹è¯•**çš„ä»·å€¼ä¸è¨€è€Œå–»ï¼Œå®ƒå¸®æˆ‘ä»¬æå‰è§„é¿äº†ç¯å¢ƒé—®é¢˜ï¼ŒèŠ‚çœäº†å¤§é‡æ—¶é—´ã€‚**ä»£ç çš„å¯å¤ç°æ€§**ä¹Ÿè‡³å…³é‡è¦ï¼Œå°†æ•´ä¸ªæµç¨‹æ•´åˆåˆ°ä¸€ä¸ªçº¿æ€§çš„Notebookä¸­ï¼Œä¸ä»…æ–¹ä¾¿è‡ªå·±å›é¡¾ï¼Œä¹Ÿè®©å…¶ä»–äººèƒ½å¤Ÿè½»æ¾å¤ç°æˆ‘çš„å·¥ä½œã€‚\n",
    "\n",
    " **æœªæ¥çš„å¯ä¼˜åŒ–æ–¹å‘**:\n",
    " å¦‚æœæ—¶é—´å…è®¸ï¼Œæˆ‘è¿˜ä¼šå°è¯•ä»¥ä¸‹å‡ ä¸ªæ–¹å‘ï¼š\n",
    " 1.  **æŸå¤±å‡½æ•°**ï¼šå°è¯•ä½¿ç”¨å¦‚Focal Lossæˆ–EIoU Lossç­‰æ›´å…ˆè¿›çš„æŸå¤±å‡½æ•°ï¼Œå¯èƒ½ä¼šå¯¹éš¾æ ·æœ¬å’Œè¾¹ç•Œæ¡†å›å½’æœ‰æ›´å¥½çš„æ•ˆæœã€‚\n",
    " 2.  **æ•°æ®å¢å¼º**ï¼šå°è¯•æ›´å¤æ‚çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¦‚Albumentationsåº“ã€‚\n",
    " 3.  **æ¨¡å‹è’¸é¦**ï¼šè®­ç»ƒä¸€ä¸ªæ›´å¤§çš„æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œæ¥æŒ‡å¯¼æˆ‘ä»¬å½“å‰è¿™ä¸ªè½»é‡çº§æ¨¡å‹çš„è®­ç»ƒã€‚\n",
    "\n",
    " æ€»ä¹‹ï¼Œè¿™æ¬¡å¤§ä½œä¸šæ˜¯ä¸€æ¬¡å®è´µçš„å®æˆ˜ç»å†ï¼Œæ„Ÿè°¢è€å¸ˆå’ŒåŠ©æ•™çš„æŒ‡å¯¼ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhgsl_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
